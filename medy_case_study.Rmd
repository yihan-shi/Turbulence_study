---
title: "medy_case_study"
author: "Medy Mu"
date: '2022-10-31'
output: html_document
---

```{r}
library(glmnet)
library(splines)
library(boot)
library(gam)
library(gamreg)
```

```{r}
train <- read.csv("data-train.csv")
test <- read.csv("data-test.csv")
```

```{r}
train$Fr_factor <- factor(train$Fr)
test$Fr_factor <- factor(test$Fr)
train$Re_factor <- factor(train$Re)
test$Re_factor <- factor(test$Re)
```

```{r}
#convert to central moments
train$C_moment_1 <- 0
train$C_moment_2 <- train$R_moment_2 - (train$R_moment_1)^2
train$C_moment_3 <- train$R_moment_3 - 3*train$R_moment_1*train$R_moment_2 + 2*(train$R_moment_1)^3
train$C_moment_4 <- train$R_moment_4 - 4*train$R_moment_1*train$R_moment_3 + 6*(train$R_moment_1)^2*train$R_moment_2 -3*(train$R_moment_1)^4
```

```{r}
set.seed(1)
sub_train <- sample(1:nrow(train), nrow(train)*0.7) ## split data into train and test
sub_test <- train[-sub_train,]
sub_train <- train[sub_train,]
```

```{r}
plot(density(train$R_moment_2))
plot(density(log(train$R_moment_2)))

plot(density(train$St))

plot(density(train$Re))

plot(train$St, log(train$R_moment_2), type = "b")
plot(train$Re, log(train$R_moment_2), type = "b")
```

```{r}
# least square model
r2_ls <- lm(log(R_moment_2) ~ St + Re_factor + Fr_factor, data = sub_train)
r2_ls_int <- lm(log(R_moment_2) ~ St + Re_factor + Fr_factor + Re_factor*Fr_factor, data = sub_train)
summary(r2_ls)
summary(r2_ls_int)
```

```{r}
ls_pred <- predict(r2_ls, newdata = sub_test)
mean((sub_test$R_moment_2 - exp(ls_pred))^2)
```

```{r}
ls_pred_int <- predict(r2_ls_int, newdata = sub_test)
mean((sub_test$R_moment_2 - exp(ls_pred_int))^2)
```

```{r}
par(mfrow=c(2,2))
plot(r2_ls)
```
```{r}
par(mfrow=c(2,2))
plot(r2_ls_int)
```

```{r}
#ridge regression
train.matrix <- model.matrix (log(R_moment_2) ~ St + Re_factor + Fr_factor + Re_factor*Fr_factor, sub_train)[,-1]
test.matrix <- model.matrix (log(R_moment_2) ~ St + Re_factor + Fr_factor + Re_factor*Fr_factor, sub_test)[,-1]
test.r2 <- sub_test$R_moment_2
train.r2 <- sub_train$R_moment_2

set.seed (1)
cv.out.ridge <- cv.glmnet (train.matrix,train.r2,alpha = 0)
plot(cv.out.ridge)
```

In the plot above, the numbers across the top of the plot are the number of nonzero coefficient estimates for the model. Ridge regression does not set coefficients to 0, so all variables are included in every model. 

```{r}
bestlam.ridge <- cv.out.ridge$lambda.min
r2_ridge <- glmnet(train.matrix,train.r2,alpha=0,lambda=bestlam.ridge)

ridge.pred <- predict(r2_ridge, s = bestlam.ridge, newx = test.matrix)
mean((exp(ridge.pred) - test.r2)^2)
```

```{r}
set.seed(1)
cv.out.lasso <- cv.glmnet (train.matrix,train.r2,alpha =1)
plot(cv.out.lasso)
```

```{r}
bestlam.lasso <- cv.out.lasso$lambda.min
r2.lasso <- glmnet(train.matrix,train.r2,alpha=1,lambda=bestlam.ridge)

lasso.pred <- predict(r2.lasso,s=bestlam.lasso,newx=test.matrix)
mean((exp(lasso.pred)-test.r2)^2)
```



## Non linear modeling

### Natural spline
```{r}
RSS <- rep(0,15)
for (i in 4:15) {
model.fit <- glm(log(R_moment_2) ~ ns(St, df = i) + Re_factor + Fr_factor + Re_factor*Fr_factor, data = sub_train)
RSS[i] <- sum(model.fit$residuals^2)
}

plot(4:15, RSS[4:15], type="b", xlab="Degrees of freedom", ylab = "RSS")
title("RSS vs. Degrees of freedom")
```

```{r}
set.seed(1)
cv.err <- rep(0,15)
for (i in 4:15) {
model.fit <- glm(log(R_moment_2) ~ ns(St, df = i) + Re_factor + Fr_factor + Re_factor*Fr_factor, data = sub_train)
cv.err[i] <- cv.glm(sub_train, model.fit, K=5)$delta[1]
}

plot(4:15, cv.err[4:15], type="b", xlab="Degrees of freedom", ylab="Cross validation error")
```


```{r}
r2_spline <- glm(log(R_moment_2) ~ ns(St, df = 9) + Re_factor + Fr_factor + Re_factor*Fr_factor, data = sub_train)
attr(bs(sub_train$St, df = 9), "knots")

summary(r2_spline)
```

```{r}
par(mfrow = c(2,2))
plot(r2_spline)
```

```{r}
spline_pred <- predict(r2_spline, newdata = sub_test)
mean((sub_test$R_moment_2 - exp(spline_pred))^2)
```

```{r}
r2_gam1 <- gam(log(R_moment_2) ~ s(St, 3) + Re_factor + Fr_factor + Re_factor*Fr_factor, data = sub_train)
r2_gam2 <- gam(log(R_moment_2) ~ s(St, 5) + Re_factor + Fr_factor+ Re_factor*Fr_factor, data = sub_train)
r2_gam3 <- gam(log(R_moment_2) ~ s(St, 7) + Re_factor + Fr_factor+ Re_factor*Fr_factor, data = sub_train)
r2_gam4 <- gam(log(R_moment_2) ~ s(St, 9) + Re_factor + Fr_factor+ Re_factor*Fr_factor, data = sub_train)

```

```{r}
par(mfrow = c(1,3))
plot(r2_gam1, se = TRUE, col = "blue")
```
```{r}
par(mfrow = c(1,3))
plot(r2_gam2, se = TRUE, col = "blue")
```
 
```{r}
par(mfrow = c(1,3))
plot(r2_gam3, se = TRUE, col = "blue")
```
```{r}
par(mfrow = c(1,3))
plot(r2_gam4, se = TRUE, col = "blue")
```

```{r}
summary(r2_gam2)
```

```{r}
r2_gam3_no_int <- gam(log(R_moment_2) ~ s(St, 7) + Re_factor + Fr_factor, data = sub_train)
```

```{r}
anova(r2_gam2_no_int, r2_gam2, test = "F")
```

```{r}
gam_pred <- predict(r2_gam3, newdata = sub_test)
mean((sub_test$R_moment_2 - exp(gam_pred))^2)
```

```{r}
gam_pred_no_int <- predict(r2_gam3_no_int, newdata = sub_test)
mean((sub_test$R_moment_2 - exp(gam_pred_no_int))^2)
```


## R_moment_4

```{r}
plot(density(train$R_moment_4))
plot(density(log(train$R_moment_4)))

plot(density(train$St))

plot(density(train$Re))

plot(train$St, log(train$R_moment_4), type = "b")
plot(train$Re, log(train$R_moment_4), type = "b")
```

```{r}
# least square model
r2_ls <- lm(log(R_moment_4) ~ St + Re_factor + Fr_factor, data = sub_train)
r2_ls_int <- lm(log(R_moment_4) ~ St + Re_factor + Fr_factor + Re_factor*Fr_factor, data = sub_train)
summary(r2_ls)
summary(r2_ls_int)
```

```{r}
ls_pred <- predict(r2_ls, newdata = sub_test)
mean((sub_test$R_moment_4 - exp(ls_pred))^2)
```

```{r}
ls_pred_int <- predict(r2_ls_int, newdata = sub_test)
mean((sub_test$R_moment_4 - exp(ls_pred_int))^2)
```

```{r}
par(mfrow=c(2,2))
plot(r2_ls)
```

```{r}
par(mfrow=c(2,2))
plot(r2_ls_int)
```

```{r}
#ridge regression
train.matrix <- model.matrix (log(R_moment_4) ~ St + Re_factor + Fr_factor + Re_factor*Fr_factor, sub_train)[,-1]
test.matrix <- model.matrix (log(R_moment_4) ~ St + Re_factor + Fr_factor + Re_factor*Fr_factor, sub_test)[,-1]
test.r2 <- sub_test$R_moment_2
train.r2 <- sub_train$R_moment_2

set.seed (1)
cv.out.ridge <- cv.glmnet (train.matrix,train.r2,alpha = 0)
plot(cv.out.ridge)
```

In the plot above, the numbers across the top of the plot are the number of nonzero coefficient estimates for the model. Ridge regression does not set coefficients to 0, so all variables are included in every model. 

```{r}
bestlam.ridge <- cv.out.ridge$lambda.min
r2_ridge <- glmnet(train.matrix,train.r2,alpha=0,lambda=bestlam.ridge)

ridge.pred <- predict(r2_ridge, s = bestlam.ridge, newx = test.matrix)
mean((exp(ridge.pred) - test.r2)^2)
```

```{r}
set.seed(1)
cv.out.lasso <- cv.glmnet (train.matrix,train.r2,alpha =1)
plot(cv.out.lasso)
```

```{r}
bestlam.lasso <- cv.out.lasso$lambda.min
r2.lasso <- glmnet(train.matrix,train.r2,alpha=1,lambda=bestlam.ridge)

lasso.pred <- predict(r2.lasso,s=bestlam.lasso,newx=test.matrix)
mean((exp(lasso.pred)-test.r2)^2)
```



## Non linear modeling

### Natural spline
```{r}
RSS <- rep(0,15)
for (i in 4:15) {
model.fit <- glm(log(R_moment_4) ~ ns(St, df = i) + Re_factor + Fr_factor + Re_factor*Fr_factor, data = sub_train)
RSS[i] <- sum(model.fit$residuals^2)
}

plot(4:15, RSS[4:15], type="b", xlab="Degrees of freedom", ylab = "RSS")
title("RSS vs. Degrees of freedom")
```

```{r}
set.seed(1)
cv.err <- rep(0,15)
for (i in 4:15) {
model.fit <- glm(log(R_moment_4) ~ ns(St, df = i) + Re_factor + Fr_factor + Re_factor*Fr_factor, data = sub_train)
cv.err[i] <- cv.glm(sub_train, model.fit, K=5)$delta[1]
}

plot(4:15, cv.err[4:15], type="b", xlab="Degrees of freedom", ylab="Cross validation error")
```


```{r}
r2_spline <- glm(log(R_moment_4) ~ ns(St, df = 9) + Re_factor + Fr_factor + Re_factor*Fr_factor, data = sub_train)
attr(ns(sub_train$St, df = 9), "knots")

summary(r2_spline)
```

```{r}
par(mfrow = c(2,2))
plot(r2_spline)
```

```{r}
spline_pred <- predict(r2_spline, newdata = sub_test)
mean((sub_test$R_moment_4 - exp(spline_pred))^2)
```

```{r}
r2_gam1 <- gam(log(R_moment_4) ~ s(St, 3) + Re_factor + Fr_factor + Re_factor*Fr_factor, data = sub_train)
r2_gam2 <- gam(log(R_moment_4) ~ s(St, 5) + Re_factor + Fr_factor+ Re_factor*Fr_factor, data = sub_train)
r2_gam3 <- gam(log(R_moment_4) ~ s(St, 7) + Re_factor + Fr_factor+ Re_factor*Fr_factor, data = sub_train)
r2_gam4 <- gam(log(R_moment_4) ~ s(St, 9) + Re_factor + Fr_factor+ Re_factor*Fr_factor, data = sub_train)

```

```{r}
par(mfrow = c(1,3))
plot(r2_gam1, se = TRUE, col = "blue")
```
```{r}
par(mfrow = c(1,3))
plot(r2_gam2, se = TRUE, col = "blue")
```
 
```{r}
par(mfrow = c(1,3))
plot(r2_gam3, se = TRUE, col = "blue")
```
```{r}
par(mfrow = c(1,3))
plot(r2_gam4, se = TRUE, col = "blue")
```

```{r}
summary(r2_gam2)
```

```{r}
r2_gam3_no_int <- gam(log(R_moment_4) ~ s(St, 7) + Re_factor + Fr_factor, data = sub_train)
```

```{r}
gam_pred <- predict(r2_gam3, newdata = sub_test)
mean((sub_test$R_moment_4 - exp(gam_pred))^2)
```

```{r}
gam_pred_no_int <- predict(r2_gam3_no_int, newdata = sub_test)
mean((sub_test$R_moment_4 - exp(gam_pred_no_int))^2)
```