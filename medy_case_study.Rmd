---
title: "medy_case_study"
author: "Medy Mu"
date: '2022-10-31'
output: html_document
---

```{r}
library(glmnet)
library(splines)
library(boot)
library(gam)
library(gamreg)
```

```{r}
train <- read.csv("data-train.csv")
test <- read.csv("data-test.csv")
```

```{r}
#convert to central moments
train$C_moment_1 <- 0
train$C_moment_2 <- train$R_moment_2 - (train$R_moment_1)^2
train$C_moment_3 <- train$R_moment_3 - 3*train$R_moment_1*train$R_moment_2 + 2*(train$R_moment_1)^3
train$C_moment_4 <- train$R_moment_4 - 4*train$R_moment_1*train$R_moment_3 + 6*(train$R_moment_1)^2*train$R_moment_2 -3*(train$R_moment_1)^4
```

```{r}
train$Fr_factor <- factor(train$Fr)
test$Fr_factor <- factor(test$Fr)
```

```{r}
plot(density(train$R_moment_2))
plot(density(log(train$R_moment_2)))

plot(density(train$St))

plot(density(train$Re))

plot(train$St, log(train$R_moment_2), type = "b")
plot(train$Re, log(train$R_moment_2), type = "b")
```

```{r}
# least square model
r2_ls_1 <- lm(log(R_moment_2) ~ St + Re + Fr_factor, data = train)
r2_ls <- lm(log(R_moment_2) ~ St + Re + Fr_factor + Re*Fr_factor, data = train)
summary(r2_ls)
ls_pred <- predict(r2_ls, newdata = train)
mean((train$R_moment_2 - ls_pred)^2)
```

```{r}
par(mfrow=c(2,2))
plot(r2_ls)
```


```{r}
#ridge regression
train.matrix <- model.matrix (log(R_moment_2) ~ St + Re + Fr_factor + Re*Fr_factor,train)[,-1]
train.r2 <- train$R_moment_2

set.seed (1)
cv.out.ridge <- cv.glmnet (train.matrix,train.r2,alpha = 0)
plot(cv.out.ridge)
```

In the plot above, the numbers across the top of the plot are the number of nonzero coefficient estimates for the model. Ridge regression does not set coefficients to 0, so all variables are included in every model. 

```{r}
bestlam.ridge <- cv.out.ridge$lambda.min
r2_ridge <- glmnet(train.matrix,train.r2,alpha=0,lambda=bestlam.ridge)

ridge.pred <- predict(r2_ridge, s = bestlam.ridge, newx = train.matrix)
mean((ridge.pred - train.r2)^2)
```

## Non linear modeling

```{r}
RSS <- rep(0,15)
for (i in 4:15) {
model.fit <- glm(log(R_moment_2) ~ bs(St, df = i) + Re + Fr_factor + Re*Fr_factor, data = train)
RSS[i] <- sum(model.fit$residuals^2)

}

plot(4:15, RSS[4:15], type="b", xlab="Degrees of freedom", ylab = "RSS")
title("RSS vs. Degrees of freedom")
```

```{r}
set.seed(1)
cv.err <- rep(0,15)
for (i in 4:15) {
model.fit <- glm(log(R_moment_2) ~ bs(St, df = i) + Re + Fr_factor + Re*Fr_factor, data = train)
cv.err[i] <- cv.glm(train, model.fit, K=10)$delta[1]
}

plot(4:15, cv.err[4:15], type="b", xlab="Degrees of freedom", ylab="Cross validation error")
```


```{r}
r2_spline <- glm(log(R_moment_2) ~ bs(St, df = 7) + Re + Fr_factor + Re*Fr_factor, data = train)
attr(bs(train$St, df = 7), "knots")

summary(r2_spline)
```

```{r}
par(mfrow = c(2,2))
plot(r2_spline)
```

```{r}
r2_gam1 <- gam(log(R_moment_2) ~ s(St, 3) + Re + Fr_factor + Re*Fr_factor, data = train)
r2_gam2 <- gam(log(R_moment_2) ~ s(St, 5) + Re + Fr_factor+ Re*Fr_factor, data = train)
r2_gam3 <- gam(log(R_moment_2) ~ s(St, 7) + Re + Fr_factor+ Re*Fr_factor, data = train)
r2_gam4 <- gam(log(R_moment_2) ~ s(St, 9) + Re + Fr_factor+ Re*Fr_factor, data = train)

```

```{r}
par(mfrow = c(1,3))
plot(r2_gam1, se = TRUE, col = "blue")
```
```{r}
par(mfrow = c(1,3))
plot(r2_gam2, se = TRUE, col = "blue")
```
 
```{r}
par(mfrow = c(1,3))
plot(r2_gam3, se = TRUE, col = "blue")
```
```{r}
par(mfrow = c(1,3))
plot(r2_gam4, se = TRUE, col = "blue")
```

```{r}
summary(r2_gam2)
```
```{r}
r2_gam2_no_int <- gam(log(R_moment_2) ~ s(St, 5) + Re + Fr_factor, data = train)
```

```{r}
anova(r2_gam2_no_int, r2_gam2, test = "F")
```



